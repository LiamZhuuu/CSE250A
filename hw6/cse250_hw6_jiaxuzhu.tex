\documentclass{article}
\usepackage[left=3cm,right=3cm,top=2cm,bottom=2cm]{geometry} % page settings
\usepackage{amsmath} % provides many mathematical environments & tools
\usepackage{graphicx}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{mathtools}
\usepackage{textcomp}

\setlength{\parindent}{0mm}
\makeatletter
\setlength{\@fptop}{0pt}
\makeatother
\def\BState{\State\hskip-\ALG@thistlm}

\newcommand{\RNum}[1]{\uppercase\expandafter{\romannumeral #1\relax}}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}


\begin{document}

\title{CSE 250A: Assignment 6}
\author{Jiaxu Zhu~~A53094655}
\date{\today}
\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{6.1}



\subsection*{6.2 Inference in HMMs}
\subparagraph*{(a)}
\begin{eqnarray*}
	P(S_t=i | S_{t+1}=j, o_1, o_2, ..., o_T ) &=& P(S_t=i | S_{t+1}=j, o_1, o_2, ..., o_{t} )~~(d-separation~\RNum{1})\\
	&=& \frac{P(S_{t+1}=j | S_{t}=i, o_1, o_2, ..., o_{t} )P(S_t=i |o_1, o_2, ..., o_{t} )}{P(S_{t+1}=j| o_1, o_2, ..., o_{t} )}\\
	&=& \frac{P(S_{t+1}=j | S_{t}=i )P(S_t=i , o_1, o_2, ..., o_{t} )}{P(S_{t+1}=j, o_1, o_2, ..., o_{t} )}~~(d-separation~\RNum{2})\\
	&=& \frac{P(S_{t+1}=j | S_{t}=i )P(S_t=i , o_1, o_2, ..., o_{t} )}{\sum_k P(S_{t+1}=j, S_t=k, o_1, o_2, ..., o_{t} )}\\
	&=& \frac{P(S_{t+1}=j | S_{t}=i )P(S_t=i , o_1, o_2, ..., o_{t} )}{\sum_k P(S_{t+1}=j | S_t=k)P(S_t=k, o_1, o_2, ..., o_{t} )}\\
	&=& \frac{a_{ij}\alpha_{it}}{\sum_{k} a_{kj}\alpha_{kt}}
\end{eqnarray*}

\subparagraph*{(b)}
\begin{eqnarray*}
	P(S_{t+1}=j, |S_t=i , o_1, o_2, ..., o_T ) &=& P(S_{t+1}=j, |S_t=i , o_{t+1}, o_{t+2}, ..., o_T )~~(d-separation~\RNum{1}\&\RNum{2})\\
	&=& \frac{P(o_{t+1}, o_{t+2}, ..., o_T | S_{t+1}=j, S_t=i)P(S_{t+1}=j, |S_t=i )}{P(o_{t+1}, o_{t+2}, ..., o_T, |S_t=i)}\\
	&=& \frac{P(o_{t+1}|S_{t+1}=j)P(o_{t+2}, ..., o_T | S_{t+1}=j)P(S_{t+1}=j, |S_t=i )}{P(o_{t+1}, o_{t+2}, ..., o_T, |S_t=i)}~~(d-separation~\RNum{1}\&\RNum{2})\\
	&=& \frac{\beta_{j(t+1)}a_{ij}b_j(o_{t+1})}{\beta_{it}}
\end{eqnarray*}

\subparagraph*{(c)}
\begin{eqnarray*}
	P(S_{t+1}=k, |S_{t-1}=i, S_t=j , o_1, o_2, ..., o_T ) &=& P(S_{t+1}=k, | S_t=j , o_{t+1}, o_{t+2}, ..., o_T )~~(d-separation~\RNum{1}\&\RNum{2})\\
	&=& \frac{\beta_{k(t+1)}a_{jk}b_k(o_{t+1})}{\beta_{jt}}
\end{eqnarray*}

\subparagraph*{(d)}
\begin{eqnarray*}
	P(S_{t+1}=k, |S_{t-1}=i , o_1, o_2, ..., o_T ) 
	&=& \sum_j P(S_{t+1}=k, S_t=j|S_{t-1}=i , o_1, o_2, ..., o_T )\\
	&=& \sum_j P(S_{t+1}=k | S_t=j, S_{t-1}=i , o_1, o_2, ..., o_T )P(S_t=j| S_{t-1}=i , o_1, o_2, ..., o_T )\\
	&=& \sum_j \frac{\beta_{k(t+1)}a_{jk}b_k (o_{t+1})}{\beta_{jt}} \frac{\beta_{jt}a_{ij}b_j( o_{t})}{\beta_{i(t-1)}}\\
\end{eqnarray*}

\subsection*{6.3 Belief updating}
\subparagraph*{(a)}
\begin{eqnarray*}
q_{jt} &=& P(S_t = j | o_1, o_2, ..., o_t)\\
&=& \frac{P(S_t = j , o_1, o_2, ..., o_t)}{P(o_1, o_2, ..., o_t)}~~(product~rule)\\
&=&  \frac{\sum_i P(S_t = j , S_{t-1}=i, o_1, o_2, ..., o_t)}{\sum_{ik} P(S_t=k, S_{t-1}=i, o_1, o_2, ..., o_t)}~~(marginalization)\\
&=&  \frac{\sum_i P(o_t | S_t = j)P(S_t = j | S_{t-1}=i)P(S_{t-1}=i | o_1, o_2, ..., o_{t-1})P(o_1, o_2, ..., o_{t-1})}{\sum_{ik} P(o_t | S_t = k)P(S_t = k | S_{t-1}=i)P(S_{t-1}=i | o_1, o_2, ..., o_{t-1})P(o_1, o_2, ..., o_{t-1})}~~(product + d-separation~\RNum{1})\\
&=&\frac{b_j(o_t) \sum_i a_{ij}q_{it-1}}{\sum_{ik} b_j(o_t)a_{ik}q_{it-1}}
\end{eqnarray*}

\subparagraph*{(b)}
\begin{eqnarray*}
	P(x_t | y_1, y_2, ..., y_t) 
	&=& \frac{P(x_t , y_1, y_2, ..., y_t)}{P(y_1, y_2, ..., y_t)}~~(product~rule)\\
	&=&  \frac{\int dx_{t-1}P(x_t , x_{t-1}, y_1, y_2, ..., y_t)}{\int dx_{t}\int dx_{t-1}P(x_t , x_{t-1}, y_1, y_2, ..., y_t)}~~(marginalization)\\
	&=&  \frac{\int dx_{t-1} P(y_t | x_t)P(x_t = j | x_{t-1})P(x_{t-1} | y_1, y_2, ..., y_{t-1})P(y_1, y_2, ..., y_{t-1})}{\int dx_{t} \int dx_{t-1} P(y_t | x_t)P(x_t = j | x_{t-1})P(x_{t-1} | y_1, y_2, ..., y_{t-1})P(y_1, y_2, ..., y_{t-1})}~~(product + d-separation~\RNum{1})\\
	&=&\frac{P(y_t | x_t) \int dx_{t-1} P(x_t | x_{t-1})P(x_{t-1} | y_1, y_2, ..., y_{t-1})}{\int dx_{t}P(y_t | x_t) \int dx_{t-1} P(x_t | x_{t-1})P(x_{t-1} | y_1, y_2, ..., y_{t-1})}
\end{eqnarray*}

The reason why this real-time updating difficult for all but Gaussian random variables is that 
\subsection*{6.4 Continuous density HMM}
\subparagraph*{(a)}
The distribution $P(X_t | S_{t-1})$ is a mixture of univariate Gaussians.
It contains n mixture components because it can be written as
\begin{eqnarray*}
	P(X_t | S_{t-1}) &=& \sum_{i=1}^{n} P(X_t, S_t = i| S_{t-1})\\
	&=& \sum_{i=1}^{n} P(X_t |S_t = i)P(S_t = i | S_{t-1})\\
\end{eqnarray*}

\subparagraph*{(b)}
The distribution $P(X_t , X_{t'}| S_t , S_{t'})$ is not a mixture of univariate Gaussians.
It is a product of Gaussians because it can be written as
\begin{eqnarray*}
	P(X_t , X_{t'}| S_t , S_{t'}) &=& P(X_t| S_t , S_{t'})P( X_{t'}| S_t , S_{t'})\\ 
	&=& P(X_t| S_t)P( X_{t'}| S_{t'})\\
\end{eqnarray*}

\subparagraph*{(c)}
The distribution $P(X_1, X_2, ..., X_T)$ is not a mixture of univariate Gaussians.
It is a product of Gaussians because it can be written as
\begin{eqnarray*}
	P(X_1, X_2, ..., X_T) &=& \sum_{S'} P(S', X_1, X_2, ..., X_T)\\
	&=& \sum_{i_1=1}^{n}\sum_{i_2=1}^{n}\cdots\sum_{i_T=1}^{n}P(S_1 = i_1)\prod_{t=2}^{T}P(S_t = i_t | S_{t-1} = i_{t-1})\prod_{t=1}^{T}P(S_t = i_t | X_t)
\end{eqnarray*}

\subparagraph*{(d)}
The distribution $P(X_t | X_1, X_2, ..., X_{t-1})$ is a mixture of univariate Gaussians.
It contains $n^2$ mixture components because it can be written as
\begin{eqnarray*}
	P(X_t | X_1, X_2, ..., X_{t-1}) &=& \sum_{i=1}^n \sum_{j=1}^n P(X_t , S_t = i, S_{t-1} = j| X_1, X_2, ..., X_{t-1})\\
	&=& \sum_{i=1}^n \sum_{j=1}^n P(X_t | S_t = i, S_{t-1} = j)P(S_t = i, S_{t-1} = j| X_1, X_2, ..., X_{t-1})\\
	&=& \sum_{i=1}^n \sum_{j=1}^n P(X_t | S_t = i)P(S_t = i | S_{t-1} = j)P(S_{t-1} = j |  X_1, X_2, ..., X_{t-1})\\
	&=& \sum_{i=1}^n \sum_{j=1}^n P(X_t | S_t = i)P(S_t = i | S_{t-1} = j)\frac{P(X_{t-1}| S_{t-1} = j,  X_1, X_2, ..., )}{den}P(S_{t-1} = j |  X_1, X_2, ..., X_{t-1})\\
\end{eqnarray*}

\subparagraph*{(e)}
The distribution $P(X_t | X_1, X_2, ..., X_{t-1})$ is a mixture of univariate Gaussians.
It contains $n^T$ mixture components because it can be written as
\begin{eqnarray*}
	P(X_T) &=& \sum_{i_1=1}^{n}\sum_{i_2=1}^{n}\cdots\sum_{i_T=1}^{n} P(X_T, S_1, S_2, ..., S_T)\\
	&=& \sum_{i_1=1}^{n}\sum_{i_2=1}^{n}\cdots\sum_{i_T=1}^{n}P(X_T|S_T=i_T)P(S_T=i_T|S_{T-1}=i_{t-1})\cdots  P(S_2=i_2|S_1=i_1)P(S_1 = i_1)\\
\end{eqnarray*}

\subparagraph*{(f)}
The distribution $P(X_1, X_2, ..., X_t | S_1, S_2, ..., S_t)$ is not a mixture of univariate Gaussians.
It is a product of Gaussians because it can be written as
\begin{eqnarray*}
	P(X_1, X_2, ..., X_t | S_1, S_2, ..., S_t) &=& \frac{P(X_1, X_2, ..., X_t , S_1, S_2, ..., S_t)}{P( S_1, S_2, ..., S_t)}\\
	&=& \frac{P(S_1)\prod_{t=2}^{T}P(S_t | S_{t-1})\prod_{t=1}^{T}P(S_t | X_t)}{P(S_1)\prod_{t=2}^{T}P(S_t | S_{t-1})}\\
	&=&  \prod_{t=1}^{T}P(S_t | X_t)
\end{eqnarray*}

\subsection*{6.5 Mixture model decision boundary}
\subparagraph*{(a)}
\begin{eqnarray*}
	P(y=1 | \vec{x}) &=& \frac{P (\vec{x} | y=1)P(y=1)}{P(\vec{x})}\\
	&=& \frac{P (\vec{x} | y=1)P(y=1)}{\sum_{i=0}^1 P(\vec{x}|y=i)P(y=i)}\\
	&=& \frac{\pi_1 (2\pi)^{-\frac{d}{2}}|\sum_1|^{-\frac{1}{2}}e^{-\frac{1}{2}(\vec{x}-\vec{\mu}_1)^T\sum_{1}^{-1}(\vec{x}-\vec{\mu}_1)}}{\sum_{i=0}^1 \pi_i (2\pi)^{-\frac{d}{2}}|\sum_i|^{-\frac{1}{2}}e^{-\frac{1}{2}(\vec{x}-\vec{\mu}_i)^T\sum_{i}^{-1}(\vec{x}-\vec{\mu}_i)}}\\
	&=& \frac{\pi_1 |\sum_1|^{-\frac{1}{2}}e^{-\frac{1}{2}(\vec{x}-\vec{\mu}_1)^T\sum_{1}^{-1}(\vec{x}-\vec{\mu}_1)}}{\sum_{i=0}^1 \pi_i |\sum_i|^{-\frac{1}{2}}e^{-\frac{1}{2}(\vec{x}-\vec{\mu}_i)^T\sum_{i}^{-1}(\vec{x}-\vec{\mu}_i)}}\\
\end{eqnarray*}

\subparagraph*{(b)}
\begin{eqnarray*}
	P(y=1 | \vec{x}) &=& \frac{\pi_1 |\sum|^{-\frac{1}{2}}e^{-\frac{1}{2}(\vec{x}-\vec{\mu}_1)^T\sum^{-1}(\vec{x}-\vec{\mu}_1)}}{\sum_{i=0}^1 \pi_i |\sum|^{-\frac{1}{2}}e^{-\frac{1}{2}(\vec{x}-\vec{\mu}_i)^T\sum^{-1}(\vec{x}-\vec{\mu}_i)}}\\
	&=& \frac{1}{1 +  \frac{\pi_0}{\pi_1} e^{-\frac{1}{2}(\vec{x}-\vec{\mu}_0)^T\sum^{-1}(\vec{x}-\vec{\mu}_0)+\frac{1}{2}(\vec{x}-\vec{\mu}_1)^T\sum^{-1}(\vec{x}-\vec{\mu}_1)}}\\
\end{eqnarray*}
Since $(\vec{x}-\vec{\mu}_0)^T\sum^{-1}(\vec{x}-\vec{\mu}_0) = \sum_{i=1}^{d}\sum_{j=1}^{d}(x_i - \mu_{0i})(x_j - \mu_{0j})\sum_{ij}$

\begin{eqnarray*}
	P(y=1 | \vec{x}) &=& \frac{1}{1 +  \frac{\pi_0}{\pi_1} e^{-\frac{1}{2}()}}\\
\end{eqnarray*}
\end{document}



